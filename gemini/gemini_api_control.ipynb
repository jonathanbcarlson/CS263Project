{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "63ba837c-ccfa-4fa6-a013-67ee6cc2bf62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "\n",
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d9e8dee2-7f13-4bef-94ae-ed6a97456f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cab33e06-6732-4bed-881b-1fba28523655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-1.0-pro\n",
      "models/gemini-1.0-pro-001\n",
      "models/gemini-1.0-pro-latest\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-001\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-pro-001\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-pro\n",
      "models/gemini-pro-vision\n"
     ]
    }
   ],
   "source": [
    "for m in genai.list_models():\n",
    "  if 'generateContent' in m.supported_generation_methods:\n",
    "    print(m.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2e59b115-ad7b-4bd9-9317-0bc9742ebec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gemini-1.5-pro\"\n",
    "model = genai.GenerativeModel(model_name=model_name)\n",
    "\n",
    "delay_seconds = 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6eeef4b0-b14d-4eda-a23e-53fe2c592d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chat_response(model, prompt: str) -> str:\n",
    "    text_response = []\n",
    "    responses = model.generate_content(prompt, stream=True)\n",
    "    for chunk in responses:\n",
    "        text_response.append(chunk.text)\n",
    "    return \"\".join(text_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3f9a8c-3f52-452a-9d63-26a7c635bdf0",
   "metadata": {},
   "source": [
    "## Physical Temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e447bf84-89f5-454e-b2aa-a7c2bbb842ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini: 2 Human: 3\n",
      "Gemini: 4 Human: 1\n",
      "Gemini: 2 Human: 3\n",
      "Gemini: 3 Human: 1\n",
      "Gemini: 1 Human: 1\n",
      "Gemini: 3 Human: 3\n",
      "Gemini: 4 Human: 4\n",
      "Gemini: 4 Human: 2\n",
      "Gemini: 1 Human: 1\n",
      "Gemini: 3 Human: 3\n",
      "Gemini: 2 Human: 1\n",
      "Gemini: 2 Human: 2\n",
      "Gemini: 2 Human: 4\n"
     ]
    }
   ],
   "source": [
    "with open(\"../physical-temporal/physical-temporal-control.json\") as f:\n",
    "    physical_temporal_prompts = json.load(f)\n",
    "    for entry in physical_temporal_prompts:\n",
    "        response = get_chat_response(model, entry[\"prompt\"])\n",
    "        if \"responses\" not in entry:\n",
    "            entry[\"responses\"] = {}\n",
    "        entry[\"responses\"][model_name] = response.strip()\n",
    "        print(\"Gemini:\", response.strip(), \"Human:\", entry[\"human_annotation\"])\n",
    "        time.sleep(delay_seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "67e2bfeb-6f31-4918-bbb8-307b171714b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.46153846153846156\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0\n",
    "for entry in physical_temporal_prompts:\n",
    "    if entry[\"human_annotation\"] == int(entry[\"responses\"][model_name]):\n",
    "        num_correct += 1\n",
    "print(\"Accuracy:\", num_correct/len(physical_temporal_prompts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9da83321-c9ba-40a6-9603-c5e2a5bb71b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../physical-temporal/physical-temporal-control.json\", \"w\", encoding=\"utf-8\") as output_file:\n",
    "    json.dump(physical_temporal_prompts, output_file, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93980dd-8f7a-4c43-bc5e-1293124689e7",
   "metadata": {},
   "source": [
    "## Spatial Temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ec87b26d-96d9-4f32-a93b-40793e0851d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini: 1 Human: 1\n",
      "Gemini: 1 Human: 3\n",
      "Gemini: 3 Human: 3\n",
      "Gemini: 4 Human: 4\n",
      "Gemini: 1 Human: 2\n",
      "Gemini: 1 Human: 1\n",
      "Gemini: 1 Human: 1\n",
      "Gemini: 1 Human: 3\n",
      "Gemini: 1 Human: 1\n",
      "Gemini: 1 Human: 3\n",
      "Gemini: 3 Human: 4\n",
      "Gemini: 3 Human: 2\n",
      "Gemini: 1 Human: 4\n",
      "Gemini: 3 Human: 3\n"
     ]
    }
   ],
   "source": [
    "with open(\"../spatial-temporal/spatial-temporal-control.json\") as f:\n",
    "    spatial_temporal_prompts = json.load(f)\n",
    "    for entry in spatial_temporal_prompts:\n",
    "        response = model.generate_content(entry[\"prompt\"])\n",
    "        if \"responses\" not in entry:\n",
    "            entry[\"responses\"] = {}\n",
    "        entry[\"responses\"][model_name] = response.text.strip()\n",
    "        print(\"Gemini:\", response.text.strip(), \"Human:\", entry[\"human_annotation\"])\n",
    "        time.sleep(delay_seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "86bb6506-4ba6-4539-9bea-963023d8337f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0\n",
    "for entry in spatial_temporal_prompts:\n",
    "    if entry[\"human_annotation\"] == int(entry[\"responses\"][model_name]):\n",
    "        num_correct += 1\n",
    "print(\"Accuracy:\", num_correct/len(spatial_temporal_prompts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9a0e5f93-3c82-4cd5-ac3f-fab997fe4135",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../spatial-temporal/spatial-temporal-control.json\", \"w\", encoding=\"utf-8\") as output_file:\n",
    "    json.dump(spatial_temporal_prompts, output_file, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ff9257-4b37-49e3-858b-f46676ed812e",
   "metadata": {},
   "source": [
    "# Spatial Physical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8b36b0cc-cf6d-42fa-bf13-102f002b747b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini: 3 Human: 4\n",
      "Gemini: 1 Human: 1\n",
      "Gemini: 4 Human: 1\n",
      "Gemini: 4 Human: 1\n",
      "Gemini: 3 Human: 4\n",
      "Gemini: 3 Human: 3\n",
      "Gemini: 3 Human: 2\n",
      "Gemini: 1 Human: 1\n",
      "Gemini: 3 Human: 2\n",
      "Gemini: 3 Human: 4\n",
      "Gemini: 1 Human: 1\n",
      "Gemini: 1 Human: 1\n",
      "Gemini: 1 Human: 2\n",
      "Gemini: 1 Human: 1\n"
     ]
    }
   ],
   "source": [
    "with open(\"../spatial-physical/spatial-physical-control.json\") as f:\n",
    "    spatial_physical_prompts = json.load(f)\n",
    "    for entry in spatial_physical_prompts:\n",
    "        response = model.generate_content(entry[\"prompt\"])\n",
    "        if \"responses\" not in entry:\n",
    "            entry[\"responses\"] = {}\n",
    "        entry[\"responses\"][model_name] = response.text.strip()\n",
    "        print(\"Gemini:\", response.text.strip(), \"Human:\", entry[\"human_annotation\"])\n",
    "        time.sleep(delay_seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "326bce71-b06f-4a07-b889-454e3e45206b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.42857142857142855\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0\n",
    "for entry in spatial_physical_prompts:\n",
    "    if entry[\"human_annotation\"] == int(entry[\"responses\"][model_name]):\n",
    "        num_correct += 1\n",
    "print(\"Accuracy:\", num_correct/len(spatial_physical_prompts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0267b971-63eb-4ff3-bb05-3618d13d389e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../spatial-physical/spatial-physical-control.json\", \"w\", encoding=\"utf-8\") as output_file:\n",
    "    json.dump(spatial_physical_prompts, output_file, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fe8e30-2ca6-47f5-9895-0331caf9a1da",
   "metadata": {},
   "source": [
    "## Spatial Temporal Physical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "22963ac7-6c36-414e-b4b1-566635495b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini: 1 Human: 4\n",
      "Gemini: 3 Human: 4\n",
      "Gemini: 2 Human: 3\n",
      "Gemini: 1 Human: 2\n",
      "Gemini: 1 Human: 2\n",
      "Gemini: 1 Human: 2\n",
      "Gemini: 4 Human: 2\n",
      "Gemini: 2 Human: 4\n",
      "Gemini: 1 Human: 1\n",
      "Gemini: 2 Human: 2\n",
      "Gemini: 1 Human: 4\n",
      "Gemini: 3 Human: 2\n",
      "Gemini: 2 Human: 2\n",
      "Gemini: 1 Human: 3\n",
      "Gemini: 3 Human: 2\n"
     ]
    }
   ],
   "source": [
    "with open(\"../spatial-temporal-physical/spatial-temporal-physical-control.json\") as f:\n",
    "    spatial_temporal_physical_prompts = json.load(f)\n",
    "    for entry in spatial_temporal_physical_prompts:\n",
    "        response = get_chat_response(model, entry[\"prompt\"])\n",
    "        if \"responses\" not in entry:\n",
    "            entry[\"responses\"] = {}\n",
    "        entry[\"responses\"][model_name] = response.strip()\n",
    "        print(\"Gemini:\", response.strip(), \"Human:\", entry[\"human_annotation\"])\n",
    "        time.sleep(delay_seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "789fd1c4-5e32-4bf2-a0fa-043f0b8dbef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0\n",
    "for entry in spatial_temporal_physical_prompts:\n",
    "    if entry[\"human_annotation\"] == int(entry[\"responses\"][model_name]):\n",
    "        num_correct += 1\n",
    "print(\"Accuracy:\", num_correct/len(spatial_temporal_physical_prompts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bdb385a1-ad09-4b0b-b127-96581524964b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../spatial-temporal-physical/spatial-temporal-physical-control.json\", \"w\", encoding=\"utf-8\") as output_file:\n",
    "    json.dump(spatial_temporal_physical_prompts, output_file, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2c19c6-bbbe-4443-9ac7-7b66a0fdc0b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
